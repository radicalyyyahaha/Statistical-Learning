{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "\n",
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        label_encoder = LabelEncoder()\n",
    "        self.data['Species'] = label_encoder.fit_transform(self.data['Species'])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'features': torch.tensor(self.data.iloc[idx, 1:5].values, dtype=torch.float32),\n",
    "            'label': torch.tensor(self.data.iloc[idx, 5], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = './data/Iris.csv'\n",
    "iris_dataset = IrisDataset(csv_file)\n",
    "\n",
    "dataset_size = len(iris_dataset)\n",
    "train_size = int(0.6 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(iris_dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, sample in enumerate(dataloader):\n",
    "        X, y = sample['features'].to(device), sample['label'].to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch, sample in enumerate(dataloader):\n",
    "            X, y = sample['features'].to(device), sample['label'].to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.560161  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.093398 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.101016  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 31.7%, Avg loss: 1.010000 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.974854  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 0.980239 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.907147  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.981174 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.907235  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.951560 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.952070  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.942523 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.892347  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.903775 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.871230  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.898578 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.865168  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.878554 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.835433  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.861914 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.798857  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.844931 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.787847  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.820291 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.833867  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.844449 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.818301  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.798207 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.773967  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.813775 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.848216  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.799184 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.616157  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.753152 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.572168  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.746728 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.673729  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.747179 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.716105  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.706875 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.620319  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.681934 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.649238  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.668098 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.612807  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.690608 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.611375  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.647861 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.655161  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.652296 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.583701  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.631866 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.624573  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.638191 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.525136  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.604928 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.570823  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.602006 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.605250  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.603120 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.732848  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.628836 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.615324  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.590487 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.466047  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.563497 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.472583  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.554932 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.507812  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.548486 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.546623  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.557900 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.613284  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.613449 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.656373  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.553284 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.512887  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.528276 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.539867  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.529957 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.578263  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.519343 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.389385  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.517257 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.493755  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.500829 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.544463  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.518459 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.460222  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.511186 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.486655  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.496117 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.250646  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.514773 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.429711  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.493859 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.436609  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.476108 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.417014  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.509764 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.375385  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.473341 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.382380  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.483777 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.354292  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.488828 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.389539  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.455958 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.374953  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.454320 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.523977  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.460442 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.384753  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.450429 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.495630  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.485289 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.336357  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.436513 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.371732  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.442372 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.415625  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.429698 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.394081  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.426716 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.352595  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.422955 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.408708  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.453208 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.487025  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.433016 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.429426  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.415481 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.423955  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.448913 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.249127  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.437171 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.438133  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.412880 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.270206  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.419671 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.396362  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.421624 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.393325  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.425893 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.384874  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.398278 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.305338  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.402869 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.331438  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.405069 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.385734  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.402112 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.364966  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.406394 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.225292  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.402641 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.380304  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.380799 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.459520  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.422976 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.386664  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.384780 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.412027  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.385146 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.391387  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.375799 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.357638  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.371383 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.224023  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.391029 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.350343  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.366334 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.339440  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.365665 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.326604  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.363216 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.330745  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.368972 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.334069  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.358766 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.425938  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.371558 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.247317  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.374523 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.360774  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.346283 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.295081  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.345268 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.283274  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.357524 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.369316  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.340661 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.310528  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.358589 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.363073  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.344557 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.312290  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.357108 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.286632  [   16/   90]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.331663 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to Iris.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"./Model/Iris.pth\")\n",
    "print(\"Saved PyTorch Model State to Iris.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
